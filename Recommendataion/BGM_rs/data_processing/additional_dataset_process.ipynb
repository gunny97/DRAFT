{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "data = pd.read_csv('/home/keonwoo/anaconda3/envs/bgmRS/data/lead_newspaper.csv')\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: ast.literal_eval(x))\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ckpt_path = 'snunlp/KR-SBERT-V40K-klueNLI-augSTS'\n",
    "sbert_tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
    "sbert_model = AutoModel.from_pretrained(ckpt_path, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,1,2,3,4]\n",
    "a[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(tokenizer, model, text):\n",
    "\n",
    "    \n",
    "    if len(tokenizer.tokenize(text)) >= 510:\n",
    "        text = text[:510]\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    else:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        \n",
    "        o1, o2, o3 = outputs['last_hidden_state'], outputs['pooler_output'], outputs['hidden_states']\n",
    "        bertcls  = o2.squeeze().detach().numpy()\n",
    "        o1 = o1.squeeze().detach().numpy()\n",
    "        cls_token = o1[0]\n",
    "    \n",
    "\n",
    "    return cls_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    '희망적인' : '만족스러운',  # 소분류 \n",
    "    '감동적인' : '감사하는', # 소분류\n",
    "    '무서운' : '두려운',  # 불안 -> 소분류\n",
    "    '로맨틱한' : '느긋', # 소분류\n",
    "    '평화로운' : '편안한', # 소분류 good\n",
    "    '멋진' : '자신하는', # 소분류\n",
    "    '우스운' : '흥분', # 소분류\n",
    "    '신나는' : '신이 난', # 소분류\n",
    "    '쿨한' : '안도' # 소분류\n",
    "}\n",
    "\n",
    "tag_emb = []\n",
    "\n",
    "for k in label_dict.keys():\n",
    "    tag_emb.append(encode_sentence(sbert_tokenizer, sbert_model, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "label_list = []\n",
    "for text in data['text']:\n",
    "\n",
    "    kk = encode_sentence(sbert_tokenizer, sbert_model, text)\n",
    "    cos_sim = cosine_similarity([kk], tag_emb)\n",
    "    if np.max(cos_sim) < 0.25:\n",
    "        label = None\n",
    "    else:\n",
    "        arg = np.argmax(cos_sim)\n",
    "        label = list(label_dict.keys())[arg]\n",
    "    label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.concat([pd.DataFrame(label_list,columns=['label']),data['text']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(news_data['label'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data[news_data['label'] != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“올해 총물동량 3억톤, 컨테이너 245만TEU 목표” 이성훈 sinawi@hanmail.net 석유화학부두 저장시설 설치, 신사업 적극 추진 지난해 3월 17일 취임한 방희석 여수광양항만공사 사장이 취임 1주년을 맞았다. 방 사장은 취임 후 여수광양항 물동량 증대와 공사 부채 해소를 통한 재무건전성 강화, 미래성장 신사업 발굴 등 지속가능한 경영과 경쟁력 강화에 역점을 뒀다. 또한 공기업으로서의 공적기능 확충과 정부 정책의 적극적인 이행, 동반성장 및 사회공헌 활동 등 국민으로부터 신뢰받는 공기업의 위상을 제고하는데 앞장 서 왔다는 평가다. 방 사장은“광양항 컨테이너 물동량 증대뿐만 아니라 철강, 석유화학, 자동차 등 글로벌 복합물류항만으로 성장시키기 위한 다양한 제도를 지속적으로 강화해 나갈 것”이라며“차질없는 미래 신성장 사업 추진 등 광양항 활성화에 최선을 다할 것”이라고 말했다. 방 사장은 올해 추진사업으로“컨테이너 물동량 증가와 연계된 인센티브 제도를 강화할 것”이라며“총물동량 3억톤, 컨테이너물동량 245만TEU, 매출액 1163억원 등 경영 목표를 달성해 나가겠다”고 다짐했다. 이어“미래 신성장 사업을 차질없이 추진하는 한편, 광양항 활성화를 위한 다양한 사업을 추진할 계획이다”고 밝혔다. 이를 살펴보면 해양산업클러스터 구축을 위해 항만물류 R&D 관련 기업의 수요를 조사하고 유관기관과 공동으로 기업 및 투자 유치를 추진할 방침이다. 석유화학부두 저장시설 설치사업은 연내에 착공하고 이를 위한 저장시설 운영사 모집 및 선정, 용역결과 기반 기본 및 실시설계에 들어갈 계획이다. 리스컨테이너 장치장 확보사업도 올 상반기 시설 준공 및 운영 개시를 목표로 세척 및 세척시설 설치공사에 들어갈 예정이다. 방 사장은“자동차 환적중심기지 육성 사업으로 자동차부두 생산성 제고 및 자동차 환적 물량 증대에 대응하기 위한 초대형 자동차전용부두를 확보할 것”이라며“포장공사가 완료된 광양항 컨테이너부두 19, 20번 선석은 자동차부두로 운영해 일시장치능력 4만대, 연간 자동차 환적 처리능력 150만대 이상으로 확대할 계획이다”고 설명했다. 컨테이너 물동량 증대 대책으로는 우선적으로 화물 창출과 직결된 새로운 인센티브 제도 시행과 지원 예산을 기존 53억원에서 올해는 132억원으로 늘려 강력한 물동량 유인책을 마련할 계획이다. 광양항 석유화학부두내 저장시설 구축사업도 관심이다. 광양항내 석유화학부두 물동량 증가에 따라 체선율이 계속 증가하고 있는 추세이며, 앞으로도 석화부두 이용 물동량은 더욱 증가할 것으로 예상된다. 방희석 사장은 이에“총 사업비 267억원을 투자해 2018년부터 2020년 기간 5000kl 용량의 액체화물 저장시설 5기, 3000kl 용량의 액체 및 가스화물 저장시설 2기를 확보할 계획이다”고 밝혔다. 이를 통해 석유화학부두의 체선율이 기존 대비 약 11.7% 감소할 것으로 추정되며, 화주사에게는 연간 약 10억원의 체선비용 절감효과가 발생할 것으로 기대된다. 방희석 사장은“소임이 다하는 날까지 ‘333+’달성 목표로 임하겠다”고 강조했다. ‘333+’는 임기 동안 총물동량 3억톤, 컨테이너물동량 300만TEU, 부채비율 30% 이하 달성과 함께 자회사 포함 직원 300명 목표를 말한다. 방 사장은 끝으로 “앞으로 공적기능을 확충하고 지금까지 부족했던 점은 더욱 보완해 나가면서 봉사하는 마음과 낮은 자세로 매사에 최선을 다하겠다”고 약속했다.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.iloc[124]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bgmRS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97f12e04903685b25708d91ecd1d4aa07ab7b586436cb43ce5df299ed23dfd1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
